{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5191eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaae1110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([896, 104], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=make_classification(n_samples=1000,n_features=20,n_informative=2,n_redundant=8,weights=[0.9,0.1],flip_y=0.01,random_state=42)\n",
    "\n",
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78046656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6568e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       174\n",
      "           1       0.75      0.46      0.57        26\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.84      0.72      0.76       200\n",
      "weighted avg       0.90      0.91      0.90       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "log_reg=LogisticRegression(C=1,solver='liblinear')\n",
    "log_reg.fit(x_train,y_train)\n",
    "y_pred_log=log_reg.predict(x_test)\n",
    "print(classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc67d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       174\n",
      "           1       0.91      0.77      0.83        26\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.94      0.88      0.91       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf_clf=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf_clf.fit(x_train,y_train)\n",
    "y_pred_rf=rf_clf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b52d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/150.0 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------------------------------------- 1.6/150.0 MB 3.0 MB/s eta 0:00:50\n",
      "    --------------------------------------- 2.4/150.0 MB 3.4 MB/s eta 0:00:44\n",
      "    --------------------------------------- 3.7/150.0 MB 3.9 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 4.7/150.0 MB 4.3 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 5.8/150.0 MB 4.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 6.8/150.0 MB 4.4 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 7.9/150.0 MB 4.5 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 9.4/150.0 MB 4.8 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 10.7/150.0 MB 5.0 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 12.1/150.0 MB 5.1 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 13.6/150.0 MB 5.3 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 14.7/150.0 MB 5.3 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 16.3/150.0 MB 5.4 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 17.6/150.0 MB 5.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 18.9/150.0 MB 5.5 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 20.4/150.0 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 21.5/150.0 MB 5.6 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 23.1/150.0 MB 5.7 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 24.6/150.0 MB 5.8 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 26.0/150.0 MB 5.8 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 26.7/150.0 MB 5.8 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 28.0/150.0 MB 5.8 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 29.4/150.0 MB 5.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 30.7/150.0 MB 5.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 32.2/150.0 MB 5.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 33.6/150.0 MB 5.9 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 34.6/150.0 MB 5.8 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 35.7/150.0 MB 5.8 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 37.0/150.0 MB 5.8 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 38.0/150.0 MB 5.8 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 39.1/150.0 MB 5.8 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 40.1/150.0 MB 5.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 41.4/150.0 MB 5.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 42.5/150.0 MB 5.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 43.8/150.0 MB 5.7 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 44.3/150.0 MB 5.7 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 45.4/150.0 MB 5.7 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 46.1/150.0 MB 5.6 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 47.2/150.0 MB 5.6 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 49.0/150.0 MB 5.6 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 50.3/150.0 MB 5.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 51.9/150.0 MB 5.7 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 53.2/150.0 MB 5.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 54.8/150.0 MB 5.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 56.4/150.0 MB 5.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 57.7/150.0 MB 5.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 58.7/150.0 MB 5.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 60.0/150.0 MB 5.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 61.6/150.0 MB 5.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 62.9/150.0 MB 5.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 64.0/150.0 MB 5.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 65.3/150.0 MB 5.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 66.6/150.0 MB 5.8 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 68.2/150.0 MB 5.8 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 69.7/150.0 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 71.0/150.0 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 72.6/150.0 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 73.7/150.0 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 75.2/150.0 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 76.5/150.0 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 78.1/150.0 MB 5.9 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 79.2/150.0 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 80.0/150.0 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 81.8/150.0 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 83.1/150.0 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 84.4/150.0 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 86.0/150.0 MB 6.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 87.3/150.0 MB 6.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 88.9/150.0 MB 6.0 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 90.2/150.0 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 91.8/150.0 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 93.3/150.0 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 94.6/150.0 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 95.9/150.0 MB 6.0 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 97.3/150.0 MB 6.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 98.8/150.0 MB 6.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 99.9/150.0 MB 6.0 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 101.4/150.0 MB 6.0 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 103.0/150.0 MB 6.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 104.1/150.0 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 105.6/150.0 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 106.7/150.0 MB 6.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 108.3/150.0 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 109.6/150.0 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 110.9/150.0 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 112.2/150.0 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 113.5/150.0 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 115.1/150.0 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 116.1/150.0 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 117.7/150.0 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 119.0/150.0 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 120.3/150.0 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 121.6/150.0 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 122.7/150.0 MB 6.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 124.0/150.0 MB 6.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 125.6/150.0 MB 6.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 126.9/150.0 MB 6.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 128.2/150.0 MB 6.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 129.5/150.0 MB 6.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 130.8/150.0 MB 6.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 131.9/150.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 133.4/150.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 134.7/150.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 136.3/150.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 137.6/150.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 138.9/150.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 140.2/150.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 140.8/150.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.8/150.0 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 142.6/150.0 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 143.9/150.0 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 145.0/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  146.3/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  147.6/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.4/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.4/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\.conda\\envs\\genai\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:51:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       174\n",
      "           1       1.00      0.77      0.87        26\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.98      0.88      0.93       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier \n",
    "xgb_clf=XGBClassifier(use_label_encoder=False,eval_metric='logloss')\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "y_pred_xgb=xgb_clf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca0e7a",
   "metadata": {},
   "source": [
    "handle the imbalancing using a smoteTomak Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316f2ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40fe7c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([722, 722], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smote_tomek=SMOTETomek(random_state=42)\n",
    "x_train_res,y_train_res=smote_tomek.fit_resample(x_train,y_train)\n",
    "np.unique(y_train_res,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8215e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\.conda\\envs\\genai\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:56:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       174\n",
      "           1       0.81      0.81      0.81        26\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.89      0.89      0.89       200\n",
      "weighted avg       0.95      0.95      0.95       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf=XGBClassifier(use_label_encoder=False,eval_metric='logloss')\n",
    "xgb_clf.fit(x_train_res,y_train_res)\n",
    "y_pred_xgb=xgb_clf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af85329f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-3.1.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==3.1.2 (from mlflow)\n",
      "  Using cached mlflow_skinny-3.1.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<21,>=4.0.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow) (2.0.40)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (8.1.8)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.1.2->mlflow)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.2->mlflow)\n",
      "  Using cached databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: fastapi<1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (0.115.12)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (1.31.1)\n",
      "Requirement already satisfied: packaging<26 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (2.11.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.1.2->mlflow)\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (4.13.1)\n",
      "Requirement already satisfied: uvicorn<1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from mlflow-skinny==3.1.2->mlflow) (0.34.0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: tomli in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (2.2.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (310)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from matplotlib<4->mlflow) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from matplotlib<4->mlflow) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.1.2->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.2->mlflow) (2.38.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from fastapi<1->mlflow-skinny==3.1.2->mlflow) (0.45.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.2->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.2->mlflow) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from Jinja2>=3.1.2->Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.2->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.2->mlflow) (0.52b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.2->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.2->mlflow) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.2->mlflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.2->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.2->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.2->mlflow) (2025.1.31)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from uvicorn<1->mlflow-skinny==3.1.2->mlflow) (0.14.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.2->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.2->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.2->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.2->mlflow) (4.9)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.2->mlflow) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.2->mlflow) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.2->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\adity\\.conda\\envs\\genai\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.2->mlflow) (0.6.1)\n",
      "Using cached mlflow-3.1.2-py3-none-any.whl (24.7 MB)\n",
      "Using cached mlflow_skinny-3.1.2-py3-none-any.whl (1.9 MB)\n",
      "Downloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n",
      "Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: waitress, sqlparse, Mako, graphql-core, cloudpickle, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.2 cloudpickle-3.1.1 databricks-sdk-0.57.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 mlflow-3.1.2 mlflow-skinny-3.1.2 sqlparse-0.5.3 waitress-3.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f83ad39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 23:15:36 INFO mlflow.tracking.fluent: Experiment with name 'comprehensive_ml_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 23:15:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 23:15:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/08 23:15:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression - Accuracy: 0.9100, F1: 0.9005\n",
      "🏃 View run logistic_regression_run at: http://127.0.0.1:5000/#/experiments/638458303277450339/runs/c04cdcdbd0bd45ae8c2dd81929b98565\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/638458303277450339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 23:15:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 23:16:04 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\adity\\AppData\\Local\\Temp\\tmphjlp3ows\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.6.1', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/07/08 23:16:04 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\adity\\AppData\\Local\\Temp\\tmphjlp3ows\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.6.1', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/07/08 23:16:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/08 23:16:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest - Accuracy: 0.9600, F1: 0.9586\n",
      "🏃 View run random_forest_run at: http://127.0.0.1:5000/#/experiments/638458303277450339/runs/b0a4ff7479f2436ba0534964043b4493\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/638458303277450339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 23:16:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\adity\\.conda\\envs\\genai\\lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [23:16:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "c:\\Users\\adity\\.conda\\envs\\genai\\lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [23:16:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/07/08 23:16:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\adity\\AppData\\Local\\Temp\\tmptua55q1t\\model, flavor: xgboost). Fall back to return ['xgboost==3.0.2']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/07/08 23:16:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\adity\\AppData\\Local\\Temp\\tmptua55q1t\\model, flavor: xgboost). Fall back to return ['xgboost==3.0.2']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/07/08 23:16:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/08 23:16:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost - Accuracy: 0.9500, F1: 0.9500\n",
      "🏃 View run xgboost_run at: http://127.0.0.1:5000/#/experiments/638458303277450339/runs/8091cb393ae24dfe91d377ce39987a9b\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/638458303277450339\n",
      "All models logged to MLflow successfully!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced MLflow tracking with more comprehensive logging\n",
    "import mlflow\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "mlflow.set_experiment(\"comprehensive_ml_experiment\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Log multiple models for comparison\n",
    "models = {\n",
    "    \"logistic_regression\": (log_reg, y_pred_log),\n",
    "    \"random_forest\": (rf_clf, y_pred_rf),\n",
    "    \"xgboost\": (xgb_clf, y_pred_xgb)\n",
    "}\n",
    "\n",
    "for model_name, (model, predictions) in models.items():\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_run\"):\n",
    "        # Log model parameters\n",
    "        if hasattr(model, 'get_params'):\n",
    "            params = model.get_params()\n",
    "            for param_name, param_value in params.items():\n",
    "                mlflow.log_param(param_name, param_value)\n",
    "        \n",
    "        # Log metrics\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions, average='weighted')\n",
    "        recall = recall_score(y_test, predictions, average='weighted')\n",
    "        f1 = f1_score(y_test, predictions, average='weighted')\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Log model\n",
    "        if model_name == \"logistic_regression\":\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "        elif model_name == \"random_forest\":\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "        elif model_name == \"xgboost\":\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        \n",
    "        # Log dataset info\n",
    "        mlflow.log_param(\"dataset_size\", len(X))\n",
    "        mlflow.log_param(\"n_features\", X.shape[1])\n",
    "        mlflow.log_param(\"train_size\", len(x_train_res))\n",
    "        mlflow.log_param(\"test_size\", len(x_test))\n",
    "        mlflow.log_param(\"resampling_technique\", \"SMOTETomek\")\n",
    "        \n",
    "        print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "print(\"All models logged to MLflow successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b7519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'xgboost_classifier' already exists. Creating a new version of this model...\n",
      "2025/07/08 23:49:59 WARNING mlflow.tracking._model_registry.fluent: Run with id 8091cb393ae24dfe91d377ce39987a9b has no artifacts at artifact path 'model', registering model based on models:/m-eec416c605f04be4af641b02b13b7112 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest XGBoost run ID: 8091cb393ae24dfe91d377ce39987a9b\n",
      "Model URI: runs:/8091cb393ae24dfe91d377ce39987a9b/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 23:49:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_classifier, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered successfully!\n",
      "Model name: xgboost_classifier\n",
      "Version: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'xgboost_classifier'.\n"
     ]
    }
   ],
   "source": [
    "# Better approach: Get the latest run and register model automatically\n",
    "import mlflow\n",
    "\n",
    "# Set the experiment and tracking URI\n",
    "mlflow.set_experiment(\"comprehensive_ml_experiment\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Get the latest run for the XGBoost model\n",
    "experiment = mlflow.get_experiment_by_name(\"comprehensive_ml_experiment\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], \n",
    "                         filter_string=\"tags.mlflow.runName = 'xgboost_run'\",\n",
    "                         order_by=[\"start_time DESC\"],\n",
    "                         max_results=1)\n",
    "\n",
    "if len(runs) > 0:\n",
    "    latest_run_id = runs.iloc[0]['run_id']\n",
    "    model_uri = f\"runs:/{latest_run_id}/model\"\n",
    "    \n",
    "    print(f\"Latest XGBoost run ID: {latest_run_id}\")\n",
    "    print(f\"Model URI: {model_uri}\")\n",
    "    \n",
    "    # Register the model\n",
    "    try:\n",
    "        result = mlflow.register_model(model_uri=model_uri, name=\"xgboost_classifier\")\n",
    "        print(f\"Model registered successfully!\")\n",
    "        print(f\"Model name: {result.name}\")\n",
    "        print(f\"Version: {result.version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error registering model: {e}\")\n",
    "else:\n",
    "    print(\"No XGBoost runs found. Please run the model training cells first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd250bc",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: models:/xgboost_classifier/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 40.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from loaded model: [0 0 0 0]\n",
      "Loaded model accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load registered model from MLflow Model Registry\n",
    "import mlflow\n",
    "\n",
    "# Set tracking URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Method 1: Load model using the correct registered model name\n",
    "try:\n",
    "    model_name = \"xgboost_classifier\"  # This should match the registered model name\n",
    "    model_version = 1\n",
    "    model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "    \n",
    "    print(f\"Loading model from: {model_uri}\")\n",
    "    loaded_model = mlflow.xgboost.load_model(model_uri=model_uri)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_loaded = loaded_model.predict(x_test)\n",
    "    print(f\"Predictions from loaded model: {y_pred_loaded[:4]}\")\n",
    "    \n",
    "    # Evaluate the loaded model\n",
    "    accuracy = accuracy_score(y_test, y_pred_loaded)\n",
    "    print(f\"Loaded model accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nLet's check what models are available in the registry...\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49ea8e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'mlflow_simple_project'.\n",
      "Copied version '1' of model 'xgboost_classifier' to version '1' of model 'mlflow_simple_project'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1751999392813, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1751999392813, metrics=None, model_id=None, name='mlflow_simple_project', params=None, run_id='8091cb393ae24dfe91d377ce39987a9b', run_link='', source='models:/xgboost_classifier/1', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_model_uri=f\"models:/{model_name}/{model_version}\"\n",
    "prod_model=\"mlflow_simple_project\"\n",
    "client=mlflow.MlflowClient()\n",
    "client.copy_model_version(dev_model_uri,prod_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: models:/mlflow_simple_project/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 55.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from loaded model: [0 0 0 0]\n",
      "Loaded model accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load registered model from MLflow Model Registry\n",
    "import mlflow\n",
    "\n",
    "# Set tracking URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Method 1: Load model using the correct registered model name\n",
    "try:\n",
    "    model_name = \"xgboost_classifier\"  # This should match the registered model name\n",
    "    model_version = 1\n",
    "    model_uri = f\"models:/{prod_model}/{model_version}\"\n",
    "    \n",
    "    print(f\"Loading model from: {model_uri}\")\n",
    "    loaded_model = mlflow.xgboost.load_model(model_uri=model_uri)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_loaded = loaded_model.predict(x_test)\n",
    "    print(f\"Predictions from loaded model: {y_pred_loaded[:4]}\")\n",
    "    \n",
    "    # Evaluate the loaded model\n",
    "    accuracy = accuracy_score(y_test, y_pred_loaded)\n",
    "    print(f\"Loaded model accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nLet's check what models are available in the registry...\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b05c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Git commands to resolve the conflict\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_git_command(command, description):\n",
    "    \"\"\"Run a git command and print the result\"\"\"\n",
    "    print(f\"\\n🔄 {description}\")\n",
    "    print(f\"Command: {command}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True, cwd=r\"C:\\Users\\adity\\OneDrive\\Desktop\\MLOps\")\n",
    "        \n",
    "        if result.stdout:\n",
    "            print(\"✅ Output:\")\n",
    "            print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"⚠️ Messages:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "        return result.returncode == 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Step 1: Check current git status\n",
    "run_git_command(\"git status\", \"Checking current Git status\")\n",
    "\n",
    "# Step 2: Pull remote changes\n",
    "success = run_git_command(\"git pull origin main\", \"Pulling remote changes\")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✅ Pull successful! Now pushing your changes...\")\n",
    "    # Step 3: Push your changes\n",
    "    run_git_command(\"git push -u origin main\", \"Pushing your changes\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Pull failed or had conflicts. You may need to:\")\n",
    "    print(\"1. Resolve any merge conflicts manually\")\n",
    "    print(\"2. Run: git add .\")\n",
    "    print(\"3. Run: git commit -m 'Resolve merge conflicts'\")\n",
    "    print(\"4. Run: git push -u origin main\")\n",
    "    \n",
    "    # Check if there are any conflicts\n",
    "    run_git_command(\"git status\", \"Checking for merge conflicts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bbf38",
   "metadata": {},
   "source": [
    "# Git Line Ending Warning - Not an Error! ✅\n",
    "\n",
    "## What This Warning Means:\n",
    "The warning `LF will be replaced by CRLF` is **normal** and **safe** on Windows. It's just telling you that Git is handling line ending differences between:\n",
    "- **LF** (Line Feed) - Used by Unix/Linux/Mac\n",
    "- **CRLF** (Carriage Return + Line Feed) - Used by Windows\n",
    "\n",
    "## This is NOT an error - your files are fine! \n",
    "\n",
    "## Next Steps to Complete Git Push:\n",
    "\n",
    "### 1. Commit your changes:\n",
    "```bash\n",
    "git commit -m \"Add MLflow tutorial with model training and tracking\"\n",
    "```\n",
    "\n",
    "### 2. Push to GitHub:\n",
    "```bash\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "## Optional: Configure Git to Handle Line Endings Automatically\n",
    "```bash\n",
    "# Configure Git to handle line endings automatically (run once)\n",
    "git config --global core.autocrlf true\n",
    "```\n",
    "\n",
    "Your `git add .` command worked perfectly! The warning is just informational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78785c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the Git workflow - Commit and Push\n",
    "import subprocess\n",
    "\n",
    "def run_git_command(command, description):\n",
    "    \"\"\"Run a git command and print the result\"\"\"\n",
    "    print(f\"\\n🔄 {description}\")\n",
    "    print(f\"Command: {command}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True, cwd=r\"C:\\Users\\adity\\OneDrive\\Desktop\\MLOps\")\n",
    "        \n",
    "        if result.stdout:\n",
    "            print(\"✅ Output:\")\n",
    "            print(result.stdout)\n",
    "        \n",
    "        if result.stderr and \"LF will be replaced by CRLF\" not in result.stderr:\n",
    "            print(\"⚠️ Messages:\")\n",
    "            print(result.stderr)\n",
    "        elif \"LF will be replaced by CRLF\" in result.stderr:\n",
    "            print(\"ℹ️ Line ending warning (safe to ignore)\")\n",
    "            \n",
    "        return result.returncode == 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Since git add . was successful, now commit and push\n",
    "print(\"📝 Your git add . command was successful!\")\n",
    "print(\"The line ending warning is normal on Windows and can be ignored.\")\n",
    "\n",
    "# Step 1: Commit the changes\n",
    "commit_success = run_git_command(\n",
    "    'git commit -m \"Add MLflow tutorial with model training, tracking and registry\"', \n",
    "    \"Committing your changes\"\n",
    ")\n",
    "\n",
    "if commit_success:\n",
    "    # Step 2: Push to GitHub\n",
    "    push_success = run_git_command(\"git push -u origin main\", \"Pushing to GitHub\")\n",
    "    \n",
    "    if push_success:\n",
    "        print(\"\\n🎉 SUCCESS! Your MLflow tutorial has been pushed to GitHub!\")\n",
    "        print(\"You can now view it at: https://github.com/Adjadhav123/mlflow_tutorial.git\")\n",
    "    else:\n",
    "        print(\"\\n❌ Push failed. Check the output above for details.\")\n",
    "else:\n",
    "    print(\"\\n❌ Commit failed. Check the output above for details.\")\n",
    "\n",
    "# Final status check\n",
    "run_git_command(\"git status\", \"Checking final Git status\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
